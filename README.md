# Repositorio de Aprendizaje de MÃ¡quina I

- **Profesoras:** Facundo AdriÃ¡n Lucianna & MarÃ­a Carina RoldÃ¡n

- **Estudiantes:**  
	* Paola Andrea Blanco    (a2303)  
	* Facundo Manuel Quiroga (a2305)  
	* Juan Manuel Fajardo    (a2310)  
	* Victor Gabriel Peralta (a2322)  
	* AgustÃ­n JesÃºs Vazquez  (e2301)  

## DescripciÃ³n del repositorio

Este repositorio contiene el **Trabajo PrÃ¡ctico Integrador** de la materia **Aprendizaje de MÃ¡quina I**, correspondiente a la Carrera de EspecializaciÃ³n en Inteligencia Artificial (23Co2025).

El objetivo del trabajo es predecir la ocurrencia de lluvia al dÃ­a siguiente en distintas localidades de Australia, utilizando tÃ©cnicas de **aprendizaje automÃ¡tico supervisado** y datos meteorolÃ³gicos histÃ³ricos.

---

## ğŸ“Œ Objetivo
Predecir la variable binaria `RainTomorrow` (SÃ­ / No) a partir de variables meteorolÃ³gicas del dÃ­a actual, priorizando mÃ©tricas robustas frente al desbalance de clases y probabilidades bien calibradas para toma de decisiones.

## ğŸ“‚ Dataset
- **Fuente:** Rain in Australia (Kaggle)
- **Observaciones:** ~145.000
- **Variables:** 23 (originales)
- **Target:** `RainTomorrow`
- **DistribuciÃ³n de clases:** ~77% No / 23% SÃ­

## ğŸ” MetodologÃ­a
- AnÃ¡lisis exploratorio de datos (EDA)
- Limpieza de datos y tratamiento de valores faltantes
- Manejo de outliers (discretizaciÃ³n y capping)
- One-Hot Encoding de variables categÃ³ricas
- Escalado de variables numÃ©ricas
- Split temporal de los datos (train / test)
- Entrenamiento y evaluaciÃ³n de mÃºltiples modelos
- OptimizaciÃ³n de hiperparÃ¡metros con Optuna
- CalibraciÃ³n de probabilidades (Isotonic Regression y Platt Scaling)

## ğŸ¤– Modelos Evaluados
- RegresiÃ³n LogÃ­stica
- Naive Bayes Gaussiano
- K-Nearest Neighbors (KNN)
- Random Forest
- XGBoost

## ğŸ† Modelo Final Seleccionado
**XGBoost optimizado con calibraciÃ³n isotÃ³nica**

**JustificaciÃ³n:**
- Mayor ROC-AUC
- Mejor calibraciÃ³n de probabilidades (Brier Score mÃ¡s bajo)
- Mejor balance entre Precision y Recall
- Umbral de decisiÃ³n configurable segÃºn necesidades del negocio

## ğŸ“ˆ MÃ©tricas Utilizadas
- Accuracy
- Precision
- Recall
- F1-score
- ROC-AUC
- Brier Score
- Curvas ROC y Precisionâ€“Recall

## ğŸ“ Estructura del Repositorio
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ weatherAUS.csv
â”‚ â””â”€â”€ weatherAUS_preprocessed.csv
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ logistic_regression.py
â”‚ â”œâ”€â”€ naive_bayes.py
â”‚ â”œâ”€â”€ knn.py
â”‚ â”œâ”€â”€ random_forest.py
â”‚ â”œâ”€â”€ xgboost.py
â”‚ â”œâ”€â”€ metrics_utils.py
â”‚ â””â”€â”€ calibratecopy1.py
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ TP_Integrador_AM1.ipynb
â”œâ”€â”€ trained_models/ # opcional
â””â”€â”€ README.md

## â–¶ï¸ EjecuciÃ³n
1. Clonar el repositorio
2. Instalar las dependencias
3. Ejecutar el notebook principal: AMq_Trabajo_Final.ipynb

